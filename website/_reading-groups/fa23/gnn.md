---
layout: reading-group
name: Graph Neural Networks
sem: 2023-4
location: Open Computing Facility (OCF)
time: Monday 19:00 - 20:00 and Thursday 16:00 - 17:00
logistics: >-
    Join the discord for logistics information: https://discord.gg/W5aH8HaM4 (if the link is expired, please email ronitnath@berkeley.edu)
files: >-
    Seminar slides and notes will be posted here soon.
weeks:

  - date: Week 0 (11/6 & 11/9)
    topic: >-
        Introduction to important background topics in graph theory and machine learning, utilizing pytorch.

        *   [Week 0](https://gnn.seas.upenn.edu/lectures/lecture-1/) of Ribeiro's GNNs.
    resources: >-
        [Training models with pytorch, from the course website](https://gnn.seas.upenn.edu/pytorch/)
        

---

This reading group follows the UPenn course, "Graph Neural Networks" (ESE 5140 - https://gnn.seas.upenn.edu/lectures/). We will be following the lectures and reading the papers that are linked in the course website. We will be meeting twice a week to discuss the lectures and papers. A description from their website is provided in the final paragraph.

Our methodology is to present the course's materials to each other, in a rotating order. We encourage you to join the rotating order once you're comfortable with the materials - the best way to learn is to teach! This is meant to be a low pressure environment, your presentation doesn't need to be perfect, and it's very reasonable to accept help from the other members of the group. We will not be following the course 1:1 week for week, instead, we will be pacing ourselves appropriately for learning the contents of the course.

Graph Neural Networks (GNNs) are information processing architectures for signals supported on graphs. They have been developed and are presented in this course as generalizations of the convolutional neural networks (CNNs) that are used to process signals in time and space. Depending on how much you have heard of neural networks (NNs) and deep learning, this is a sentence that may sound strange. Aren’t CNNs just particular cases of NN? And isn’t the same true of GNNs? In a strict sense they are, but our focus on this course is in large scale problems involving high dimensional signals. In these settings NNs fail to scale. CNNs are the tool for enabling scalable learning for signals in time and space. GNNS are the tool for enabling scalable learning for signals supported on graphs.